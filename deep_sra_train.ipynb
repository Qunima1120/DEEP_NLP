{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction and validation of bioNLP named entity recognition model using deep learning\n",
    "Problems: the embeddings I trained is worse than the one from google\n",
    "\n",
    "deep_nlp_serial\n",
    "\n",
    "Attribution: \n",
    "    Some of the code are borrowed from the example code from spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/cellar/users/btsui/anaconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/btsui/anaconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "\n",
    "import random\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "import thinc.extra.datasets\n",
    "from spacy.compat import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from sklearn import model_selection\n",
    "#import seaborn as sns\n",
    "from sklearn import metrics\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in SRA data\n",
    "\n",
    "Wall time: 47.5 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.93 s, sys: 3.54 s, total: 13.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "inS_dir='/cellar/users/btsui/Data/nrnb01_nobackup/METAMAP/allSRS.pickle'\n",
    "sra_dump_pickle_dir='/cellar/users/btsui/Data/SRA/DUMP/sra_dump.pickle'\n",
    "srsS=pd.read_pickle(inS_dir)\n",
    "technical_meta_data_df=pd.read_pickle(sra_dump_pickle_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in spacy models\n",
    "\n",
    "Wall time: 52.1 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/btsui/anaconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/btsui/anaconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 5.68 s, total: 52.4 s\n",
      "Wall time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#nlp=spacy.load('en_vectors_web_lg')\n",
    "nlp=spacy.load('./wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for model compilation and feature extraction\n",
    "\n",
    "Useful information for understanding the neural network: \n",
    "\n",
    "TimeDistributed: https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "\n",
    "lr stands for: learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_lstm(embeddings, shape, settings):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            embeddings.shape[0],\n",
    "            embeddings.shape[1],\n",
    "            input_length=shape['max_length'],\n",
    "            trainable=False,\n",
    "            weights=[embeddings],\n",
    "            mask_zero=True\n",
    "        )\n",
    "    )\n",
    "    #the same dense layer is first applied extract the most useful info from embedding layers\n",
    "    model.add(TimeDistributed(Dense(shape['nr_hidden'], use_bias=False)))\n",
    "    model.add(Bidirectional(LSTM(shape['nr_hidden'],\n",
    "                                 recurrent_dropout=settings['dropout'],\n",
    "                                 dropout=settings['dropout'])))\n",
    "    model.add(Dense(shape['nr_class'], activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=settings['lr']), loss='categorical_crossentropy',\n",
    "\t\t  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = numpy.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in tqdm(enumerate(docs),total=len(docs)):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            ##rever to word vector\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset sra data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "srsWithText=srsS.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_meta_data_df_sub=technical_meta_data_df[technical_meta_data_df.Sample.isin(srsWithText)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset data based on entity types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_df=pd.read_csv('./Results/grouping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell type          16\n",
       "SCIENTIFIC_NAME    11\n",
       "geo_loc_name       10\n",
       "sex                10\n",
       "disease            10\n",
       "genotype            7\n",
       "Name: GroupName, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouping_df['GroupName'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cap contribution by each study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample_per_study_n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAttribs=grouping_df.Attributes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify: SCIENTIFIC_NAME, organism, Organism, host scientific name, Species, host, specific host, host_scientific_name, host organism, nat-host, specific_host, sex, host_sex, Sex, gender, host sex, host_gender, Gender, host-sex, SEX, GENDER, genotype, genotype/variation, plant genotype, mutant, mutation, phenotype, host_genotype, disease, tumor type, diagnosis, disease state, DiseaseState, cancer type, tumor, clinical history, disease status, cell description, cell type, cell_type, source cell type, cell types, source_name, cell-type, CellType, cell subtype, biomaterial_type, progenitor cell type, tissue/cell type, DIFFERENTIATION_STAGE, cell, differentiation status, cell line source, geo_loc_name, geographic location, geo loc name, geographic location (country and/or sea, region), geographic location (country and/or sea,region), country, \"geographic location (country and/or sea,region)\", birth_location, geographic location (country and/or sea), Geo_loc_name\n"
     ]
    }
   ],
   "source": [
    "subsampledSrs=technical_meta_data_df.groupby('Study').head(n=max_sample_per_study_n)['Sample']\n",
    "print ('classify: {}'.format(\", \".join(myAttribs)))\n",
    "m=srsS.index.get_level_values(0).isin(subsampledSrs.values)\n",
    "m1=srsS.index.get_level_values(1).isin(myAttribs)\n",
    "srsS_subS=srsS[m&m1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRS1024493  SCIENTIFIC_NAME                  Camellia oleifera\n",
       "            geo_loc_name       China: 856 m, Jinggang Mountain\n",
       "            sex                                  hermaphrodite\n",
       "SRS568274   SCIENTIFIC_NAME    Escherichia coli 2-316-03_S3_C1\n",
       "            country                                   Tanzania\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srsS_subS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTextL=['not collected','not applicable','missing','n[/]?a','unknown']\n",
    "\n",
    "filterTextRegex=\"|\".join(map(lambda myStr:'(?:{})'.format(myStr),filterTextL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_filterM=srsS_subS.str.contains(filterTextRegex,case=False)\n",
    "srsS_subS=srsS_subS[~srs_filterM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf=srsS_subS.reset_index()\n",
    "myDf.columns=['srs','attrib','sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf['sentence']=myDf['sentence'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data into training and  testing randomly by study levels\n",
    "\n",
    "It is split by study level to avoid overgeneralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/btsui/anaconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "study_S=technical_meta_data_df_sub['Study'].drop_duplicates()\n",
    "print (len(study_S))\n",
    "myNStudies=len(study_S)\n",
    "train_n=int((myNStudies*train_test_ratio))\n",
    "train_studies=study_S.sample(n=train_n,random_state=0).values\n",
    "technical_meta_data_df_sub['Train']=technical_meta_data_df_sub['Study'].isin(train_studies).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slice out the training and testing SRS ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask=technical_meta_data_df_sub['Train']\n",
    "train_samples=technical_meta_data_df_sub['Sample'][train_mask].values\n",
    "test_samples=technical_meta_data_df_sub['Sample'][~train_mask].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename the attrib based on the grouped class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf['orig_attrib']=myDf['attrib']\n",
    "AttribToGroupNameS=grouping_df.groupby('Attributes')['GroupName'].first()\n",
    "myDf['attrib']=AttribToGroupNameS[myDf['orig_attrib'].values].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrib\n",
      "SCIENTIFIC_NAME    1008762\n",
      "cell type           300054\n",
      "disease              23064\n",
      "genotype             87836\n",
      "geo_loc_name        266511\n",
      "sex                 149206\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### set training and testing within the dataframe\n",
    "all_train_df=myDf[myDf.srs.isin(train_samples)]\n",
    "g=all_train_df.groupby('attrib')\n",
    "print (g.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsetting training and testing data \n",
    "shuffle the training data to make sure the model isn't learning the ordering of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap_size=50000#20000#1000#50000\n",
    "train_df=all_train_df.sample(n=all_train_df.shape[0]).groupby('attrib').head(n=cap_size)\n",
    "all_test_df=myDf[myDf.srs.isin(test_samples)]\n",
    "test_df=all_test_df.sample(n=all_test_df.shape[0]).groupby('attrib').head(cap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_hidden=64 \n",
    "max_length=7#, #95% percentile of training phrase length from NCIT\n",
    "dropout=0.5\n",
    "learn_rate=0.001#, # General NN config\n",
    "nb_epoch=1#\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the sklearn encoder going back and forth between classes in string format and integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames=AttribToGroupNameS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(classNames)\n",
    "nr_classes=len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_shape={'nr_hidden': 64, 'max_length': max_length, 'nr_class': nr_classes}\n",
    "lstm_settings={'dropout': 0.5, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nlp.vocab.vectors.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform list of freetexts into a matrix of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell type          50000\n",
       "genotype           50000\n",
       "SCIENTIFIC_NAME    50000\n",
       "geo_loc_name       50000\n",
       "sex                50000\n",
       "disease            23064\n",
       "Name: attrib, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.attrib.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273064/273064 [00:13<00:00, 20144.77it/s]\n",
      "100%|██████████| 217788/217788 [00:08<00:00, 26697.77it/s]\n",
      "100%|██████████| 273064/273064 [00:01<00:00, 158626.43it/s]\n",
      "100%|██████████| 217788/217788 [00:01<00:00, 156111.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts=train_df.sentence.tolist()\n",
    "dev_texts=test_df.sentence.tolist()\n",
    "\n",
    "train_labels=keras.utils.to_categorical(\n",
    "    le.transform(train_df.attrib.values))\n",
    "dev_labels=keras.utils.to_categorical(le.transform(test_df.attrib.values))\n",
    "\n",
    "train_docs = list(tqdm(nlp.pipe(train_texts,n_threads=32),total=len(train_texts)))\n",
    "dev_docs = list(tqdm(nlp.pipe(dev_texts,n_threads=32),total=len(dev_texts)))\n",
    "\n",
    "train_X = get_features(train_docs, lstm_shape['max_length'])\n",
    "dev_X = get_features(dev_docs, lstm_shape['max_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "\n",
    "#26 mins per epoch, on a machine with 48 threads, might want to use GPU machine bordeaux for this \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./model/lstm.h5'\n",
    "log_dir=\"logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from IPython.utils import io\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tf_callBack=keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "call_backs = [tf_callBack,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save('./model/classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_lstm(embeddings, lstm_shape, lstm_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture keras_stdout\n",
    "lstm=model.fit(train_X, train_labels, validation_data=(dev_X, dev_labels),\n",
    "          nb_epoch=nb_epoch,verbose=1, batch_size=batch_size,callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.93458\n",
    "#print (keras_stdout)\n",
    "#ValueError: Error when checking target: expected dense_4 to have shape (46,) but got array with shape (41,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture MyTest\n",
    "#print (\"asdasd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see how training accuracy improve as the amount of data increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_stdout_str=keras_stdout.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(keras_stdout_str.split('\\r')).str.replace('\\x08','').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAcc=pd.Series(keras_stdout_str.split('\\r')).str.replace('\\x08','').str.extract('acc: (\\d+.\\d+)').dropna()[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAcc.index=trainingAcc.index*batch_size/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,0.9,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,3))\n",
    "trainingAcc.plot(ax=ax)\n",
    "#ax.set_ylabel('#')\n",
    "ax.set_xlabel('# of data point trained (thousands)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_yticks(np.arange(0.1,1.1,0.1))\n",
    "ax.get_xaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "ax.figure.savefig('./Results/Figures/data_vol__accuracy.pdf')\n",
    "ax.figure.savefig('./Results/Figures/data_vol__accuracy.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm=load_model('./model/lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_history = lstm.history['loss']\n",
    "#numpy_loss_history = numpy.array(loss_history)\n",
    "#numpy.savetxt(\"loss_history.txt\", numpy_loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_docs = list(tqdm(nlp.pipe(dev_texts,),total=len(dev_texts)))\n",
    "val_X=get_features(val_docs,lstm_shape['max_length'])\n",
    "%time predictM=lstm.model.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probaDf_multI=pd.DataFrame(data=predictM,columns=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probaDf_multI.index=pd.MultiIndex.from_arrays([test_df.attrib.values,dev_texts],names=['entity','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probaDf=probaDf_multI.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_types=probaDf.loc[:,probaDf.columns.isin(myAttribs)].idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (((probaDf.entity==predicted_types).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filterTextL=['not collected','not applicable','missing','n[/]?a']\n",
    "\n",
    "#filterTextRegex=\"|\".join(map(lambda myStr:'(?:{})'.format(myStr),filterTextL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_cleanText=~probaDf_multI.index.get_level_values('text').str.contains(filterTextRegex,case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inEvalDf=probaDf_multI#[m_cleanText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minProbThreshold=0.2\n",
    "confidence_mask=inEvalDf.max(axis=1)>=minProbThreshold\n",
    "tmpDf3=inEvalDf[confidence_mask].idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDf3.groupby('predicted').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continDf=tmpDf3.groupby(['predicted','entity']).size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continDf.columns=continDf.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribVC_train=train_df.attrib.value_counts()#.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(3,2))\n",
    "#,cmap=\"Greens\"\n",
    "continDf=continDf.loc[attribVC_train.index,attribVC_train.index]\n",
    "continDf.index=continDf.index.copy()\n",
    "continDf.columns=continDf.columns.copy()\n",
    "continDf.index.name='Predicted'\n",
    "continDf.columns.name='Actual'\n",
    "sns.heatmap(ax=ax,data=(continDf/continDf.sum(axis=0)).T*100,annot=True,cbar_kws={'label':'% of samples'},center=0.3,\n",
    "           fmt='.1f')\n",
    "fig.savefig('./Results/Figures/entity_contingency.pdf')\n",
    "fig.savefig('./Results/Figures/entity_contingency.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap((continDf.T/continDf.sum(axis=1)).T,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continDf#.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of model in validation cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,3\n",
    "                            ))\n",
    "for myClass in le.classes_: \n",
    "    fpr,tpr,_=metrics.roc_curve((probaDf.entity==myClass),probaDf[myClass])    \n",
    "    ax.plot(fpr,tpr,label=\"{myClass}  (AUC: {AUC})\".format(myClass=myClass,AUC=str(metrics.auc(fpr,tpr))[:5]))\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "for myClass in le.classes_: \n",
    "    precision,recall,_=metrics.precision_recall_curve((probaDf.entity==myClass),probaDf[myClass])    \n",
    "    ax.plot(recall, precision,label=\"{myClass}  (AUC: {AUC})\".format(myClass=myClass,AUC=str(metrics.auc(recall,precision))[:5]))\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probaDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for myClass in le.classes_: \n",
    "#    print (myClass,metrics.f1_score((probaDf.entity==myClass),probaDf[myClass]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inEvalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_a=inEvalDf.index.get_level_values('entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf=inEvalDf.idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inTmpDf['correct']=inTmpDf.entity==inTmpDf.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf.to_csv('./model/pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf[(inTmpDf.entity=='genotype')&(inTmpDf.predicted=='disease')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf.groupby('entity')['correct'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inEvalDf[entity_a=='breed'].sort_values('breed',ascending=False).index.get_level_values('text').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inEvalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculated F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "``'binary'``:\n",
    "        Only report results for the class specified by ``pos_label``.\n",
    "        This is applicable only if targets (``y_{true,pred}``) are binary.\n",
    "    ``'micro'``:\n",
    "        Calculate metrics globally by counting the total true positives,\n",
    "        false negatives and false positives.\n",
    "    ``'macro'``:\n",
    "        Calculate metrics for each label, and find their unweighted\n",
    "        mean.  This does not take label imbalance into account.\n",
    "    ``'weighted'``:\n",
    "        Calculate metrics for each label, and find their average, weighted\n",
    "        by support (the number of true instances for each label). This\n",
    "        alters 'macro' to account for label imbalance; it can result in an\n",
    "        F-score that is not between precision and recall.\n",
    "    ``'samples'``:\n",
    "        Calculate metrics for each instance, and find their average (only\n",
    "        meaningful for multilabel classification where this differs from\n",
    "        :func:`accuracy_score`).\n",
    "\"\"\"\n",
    "print( metrics.f1_score(y_true=inTmpDf['entity'],y_pred=inTmpDf['predicted'],average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdadasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for a sentence split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "sent=\"T cell is treated with LPS grow faster\"\n",
    "s=sent.split(' ')\n",
    "n_gram=2\n",
    "grams=list(map(lambda L:\" \".join(L),list(ngrams(s,n_gram))))\n",
    "print (grams)\n",
    "val_docs = list(nlp.pipe(grams))\n",
    "val_X=get_features(val_docs,lstm_shape['max_length'])\n",
    "tmpDf=pd.DataFrame(data=lstm.model.predict_proba(val_X),columns=le.classes_,index=grams)\n",
    "ax=sns.heatmap(tmpDf,cbar_kws={'label': 'Emitted probability'},annot=True)\n",
    "ax.set_ylabel('')\n",
    "ax.set_title('{} grams'.format(n_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X=get_features(val_docs,lstm_shape['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PWD/Data/DEEP_NLP/NLP_spacy/keras_on_sra_data_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tmpS3=srsS[srsS.index.get_level_values(1)=='cur_land_use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmpS3.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no data: biomass,chem_mutagen\n",
    "srsS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    by_similarity = sorted(word.vocab, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [w.orth_ for w in by_similarity[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most_similar(nlp.vocab['missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentence'][train_df['attrib']=='sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'knockdown' in nlp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['attrib']=='cell type'].sentence.str.count(' ').quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf=probaDf_multI.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf.columns=['entity','text','predicted','proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf['match']=predDf.entity==predDf.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=predDf,x='entity',y='proba',hue='match',showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf[predDf['match']].groupby(['entity'])['proba'].median().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf.groupby('proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df_sub=all_train_df[all_train_df.attrib=='SCIENTIFIC_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senVC=all_train_df_sub.sentence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senVC[senVC.index.str.contains('mouse')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeOnlyTopXTest=1000\n",
    "srsTmpDf=srsS_subS.reset_index()\n",
    "srsTmpDf.columns=['SRS','Attrib','Text']\n",
    "balancedDf=srsTmpDf.groupby(['Attrib','Text']).head(n=takeOnlyTopXTest)\n",
    "\n",
    "srsS_subS=balancedDf.set_index(['SRS','Attrib'])['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
